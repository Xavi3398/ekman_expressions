{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc6d361",
   "metadata": {},
   "source": [
    "# Normalization of LIME image explanations\n",
    "\n",
    "Normalize explanations of trained models ('model_names') on 100 samples per class from a set of datasets ('dataset_paths'). \n",
    "\n",
    "- Trained model weights loaded from 'models_save_dir'. \n",
    "\n",
    "- Evaluation results in 'results_dir' are used to select 100 positive samples of every class.\n",
    "\n",
    "- Explanations are loaded from subfolders under 'results_dir'.\n",
    "\n",
    "- Normalized explanations are stored in subfolders under 'results_dir'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3de9d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import dlib\n",
    "from PIL import Image\n",
    "\n",
    "from ekman_expressions.nets import getNetByName\n",
    "from ekman_expressions.normalization import transform_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d03373c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "model_names = ['SilNet', 'WeiNet', 'AlexNet', 'SongNet', 'InceptionV3',\n",
    "               'VGG19', 'VGG16', 'ResNet50', 'ResNet101V2', 'Xception',\n",
    "               'MobileNetV3Large', 'EfficientNetV2B0']\n",
    "\n",
    "# Number of k-cross validations and folder where they are located\n",
    "# Alternatively set the paths to the target training and test manually\n",
    "K = 5\n",
    "dataset_paths_root = '../datasets/'\n",
    "dataset_paths_train = []\n",
    "dataset_paths_test = []\n",
    "for i in range(K):\n",
    "    dataset_paths_train.append(dataset_paths_root + 'CV' + str(i+1))\n",
    "    dataset_paths_test.append(dataset_paths_root + 'CV' + str(i+1) + '_test')\n",
    "\n",
    "# Folder where the trained models were saved\n",
    "models_save_dir = '../models'\n",
    "\n",
    "# Folder where the evaluation results are saved\n",
    "results_dir = '../results'\n",
    "\n",
    "# Labels of the classes\n",
    "label_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise']\n",
    "\n",
    "# Path to the predictor file\n",
    "predictor_path = '../resources/shape_predictor_68_face_landmarks.dat'\n",
    "\n",
    "# Dimensions of normalized images\n",
    "norm_width = 224\n",
    "norm_height = 275\n",
    "vertical_space = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530c3b0d",
   "metadata": {},
   "source": [
    "## Transform LIME masks and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init progress bar\n",
    "progress = tqdm(total=len(model_names)*len(dataset_paths_train)*len(label_names)*100)\n",
    "\n",
    "# Load predictor\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "# Iterate over each net\n",
    "for model_name in model_names:\n",
    "        \n",
    "    # Load model img size\n",
    "    _, img_size = getNetByName(model_name)\n",
    "    \n",
    "    # Iterate over each CV set\n",
    "    for train_path, test_path in zip(dataset_paths_train, dataset_paths_test):\n",
    "\n",
    "        # Results foder\n",
    "        results_net = os.path.join(results_dir, model_name + '_'\n",
    "                                   + os.path.basename(train_path)\n",
    "                                   + '_results')\n",
    "\n",
    "        # 100 positives per class folder\n",
    "        imgs100 = os.path.join(results_net, 'imgs_100')\n",
    "\n",
    "        # Iterate over each class\n",
    "        for class_dir in os.listdir(imgs100):\n",
    "\n",
    "            # Path of imgs folder\n",
    "            img_path = os.path.join(imgs100, class_dir, 'positives')\n",
    "\n",
    "            # Path of LIME masks\n",
    "            exp_mask_path = os.path.join(imgs100, class_dir, 'lime_masks')\n",
    "\n",
    "            # Path of imgs with landmarks\n",
    "            positives_landmarks_path = os.path.join(imgs100, class_dir, 'positives_landmarks')\n",
    "            if not os.path.exists(positives_landmarks_path):\n",
    "                os.mkdir(positives_landmarks_path)\n",
    "\n",
    "            # Path of LIME masks with landmarks\n",
    "            lime_masks_landmarks_path = os.path.join(imgs100, class_dir, 'lime_masks_landmarks')\n",
    "            if not os.path.exists(lime_masks_landmarks_path):\n",
    "                os.mkdir(lime_masks_landmarks_path)\n",
    "\n",
    "            # Path of transformed imgs\n",
    "            positives_transformed_path = os.path.join(imgs100, class_dir, 'positives_transformed')\n",
    "            if not os.path.exists(positives_transformed_path):\n",
    "                os.mkdir(positives_transformed_path)\n",
    "\n",
    "            # Path of transformed LIME masks\n",
    "            lime_masks_transformed_path = os.path.join(imgs100, class_dir, 'lime_masks_transformed')\n",
    "            if not os.path.exists(lime_masks_transformed_path):\n",
    "                os.mkdir(lime_masks_transformed_path)\n",
    "\n",
    "            # Transform each img and mask\n",
    "            for img_name, mask_name in zip(os.listdir(img_path), os.listdir(exp_mask_path)):\n",
    "                \n",
    "                # Load image and LIME mask\n",
    "                img = Image.open(os.path.join(img_path, img_name))\n",
    "                img = img.resize((img_size, img_size))\n",
    "                img = np.array(img.convert(\"RGB\"))\n",
    "                \n",
    "                mask = cv2.imread(os.path.join(exp_mask_path, mask_name))\n",
    "            \n",
    "                # Draw landmarks on img and LIME mask, and transform both\n",
    "                img_land, lime_land, img_trans, lime_trans = transform_mask(\n",
    "                    predictor=predictor,\n",
    "                    maxx=norm_width,\n",
    "                    maxy=norm_height,\n",
    "                    vertical_space=vertical_space,\n",
    "                    image_cropped=img,\n",
    "                    image_lime=mask)\n",
    "                \n",
    "                # Save images\n",
    "                cv2.imwrite(os.path.join(positives_landmarks_path, img_name[:-4] + '_landmarks.png'), img_land)\n",
    "                cv2.imwrite(os.path.join(lime_masks_landmarks_path, img_name[:-4] + '_mask_landmarks.png'), lime_land)\n",
    "                cv2.imwrite(os.path.join(positives_transformed_path, img_name[:-4] + '_transformed.png'), img_trans)\n",
    "                cv2.imwrite(os.path.join(lime_masks_transformed_path, img_name[:-4] + '_mask_transformed.png'), lime_trans)\n",
    "\n",
    "                # Update progress\n",
    "                progress.update(1)\n",
    "\n",
    "# Close progress\n",
    "progress.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
