{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a17b846a",
   "metadata": {},
   "source": [
    "# All trainings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecd1cb4",
   "metadata": {},
   "source": [
    "Train a set of models ('model_names') on a set of datasets ('dataset_paths'). \n",
    "- Trained models stored in 'models_save_dir'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3d842b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ekman_expressions.train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3d172ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to train\n",
    "model_names = ['SilNet', 'WeiNet', 'AlexNet', 'SongNet', 'InceptionV3',\n",
    "               'VGG19', 'VGG16', 'ResNet50', 'ResNet101V2', 'Xception', \n",
    "               'MobileNetV3Large' 'EfficientNetV2B0']\n",
    "\n",
    "model_epochs = [10, 10, 10, 25, 2, \n",
    "                2, 2, 2, 2, 2, 15, 10,\n",
    "                20, 20]\n",
    "\n",
    "# Number of k-cross validations and folder where they are located\n",
    "K = 5\n",
    "dataset_paths_root = '../datasets/'\n",
    "dataset_paths_train = []\n",
    "dataset_paths_test = []\n",
    "for i in range(K):\n",
    "    dataset_paths_train.append(dataset_paths_root + 'CV' + str(i+1))\n",
    "    dataset_paths_test.append(dataset_paths_root + 'CV' + str(i+1) + '_test')\n",
    "\n",
    "# Folder to save trained models\n",
    "models_save_dir = '../models'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06511fa",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d9d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture logs\n",
    "\n",
    "# Init progress bar\n",
    "progress = tqdm(total=len(model_names)*len(dataset_paths_train))\n",
    "\n",
    "for model_name, epochs in zip(model_names, model_epochs):\n",
    "    for dataset_path, dataset_path_val in zip(dataset_paths_train, dataset_paths_test):\n",
    "\n",
    "        # Set model name\n",
    "        model_save_path = os.path.join(\n",
    "            models_save_dir,\n",
    "            model_name + '_' + os.path.basename(dataset_path))\n",
    "\n",
    "        # Train\n",
    "        train(\n",
    "            model_name=model_name,\n",
    "            dataset_path=dataset_path,\n",
    "            save_path=model_save_path,\n",
    "            dataset_path_val=dataset_path_val,\n",
    "            batch_size_train=128,\n",
    "            batch_size_val=32,\n",
    "            validation_split=0.25,\n",
    "            rescale=1./255,\n",
    "            verbose=True,\n",
    "            epochs=epochs,\n",
    "            save_weights=False)\n",
    "\n",
    "        # Update progress\n",
    "        progress.update(1)\n",
    "\n",
    "# Close progress\n",
    "progress.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
